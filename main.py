import os
import logging
import mimetypes
import requests
import time
import yt_dlp
from urllib.parse import urlparse
from pathlib import Path
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes, CallbackQueryHandler
from telegram.request import HTTPXRequest
from dotenv import load_dotenv
try:
    from pyrogram.client import Client
except ImportError:
    from pyrogram import Client
import asyncio
import glob
import concurrent.futures
from datetime import datetime, timedelta
from telegram.constants import ParseMode

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ø§Ø² ÙØ§ÛŒÙ„ .env
load_dotenv()

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø±Ø§Ú©Ø³ÛŒ Ø¨Ø±Ø§ÛŒ PythonAnywhere (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
PROXY_URL = os.getenv('PROXY_URL', None)  # Ù…Ø«Ø§Ù„: http://proxy.server:3128
# Ø§Ú¯Ø± Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ù‡Ù… Ø§Ø² Ø·Ø±ÛŒÙ‚ Ù¾Ø±Ø§Ú©Ø³ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯ (Ø¯Ø± ØµÙˆØ±ØªÛŒ Ú©Ù‡ Ù‡Ø§Ø³Øª Ù…Ù‚ØµØ¯ Ø¯Ø± whitelist Ø¨Ø§Ø´Ø¯) Ø§ÛŒÙ† Ø±Ø§ true Ú©Ù†ÛŒØ¯
ALLOW_DOWNLOAD_VIA_PROXY = os.getenv('ALLOW_DOWNLOAD_VIA_PROXY', 'false').strip().lower() in ('1','true','yes','on')
# Ø§Ú¯Ø± Ø±ÙˆÛŒ Ù‡Ø§Ø³ØªÛŒ Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ outbound Ù…Ø­Ø¯ÙˆØ¯ Ø§Ø³Øª (Ù…Ø«Ù„ PythonAnywhere Free)ØŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø­Ù„ÛŒ Ø±Ø§ ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯
DIRECT_SEND_ONLY = os.getenv('DIRECT_SEND_ONLY', 'false').strip().lower() in ('1','true','yes','on')

# Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ú©ÙˆÚ©ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ yt-dlp (Ø¨Ø±Ø§ÛŒ Ø¹Ø¨ÙˆØ± Ø§Ø² age-gate ÛŒØ§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù„Ø§Ú¯ÛŒÙ†)
YTDLP_COOKIES = os.getenv('YTDLP_COOKIES', '').strip()  # Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ú©ÙˆÚ©ÛŒ Ø¨Ù‡ ÙØ±Ù…Øª Netscape
YTDLP_COOKIE_HEADER = os.getenv('YTDLP_COOKIE_HEADER', '').strip()  # Ø±Ø´ØªÙ‡ Cookie Ø¢Ù…Ø§Ø¯Ù‡ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)

# Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø­Ø¬Ù… ÙØ§ÛŒÙ„ (MB) - Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² OOM Ø¯Ø± render.com
MAX_FILE_SIZE_MB = int(os.getenv('MAX_FILE_SIZE_MB', '2000'))  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶ 2000MB (2GB)

# Ø¢ÛŒØ¯ÛŒ Ø§Ø¯Ù…ÛŒÙ†
ADMIN_ID = 818185073

# Ø°Ø®ÛŒØ±Ù‡ Ù…ÙˆÙ‚Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ÙØ¹Ø§Ù„ (Ø¯Ø± Ø­Ø§ÙØ¸Ù‡ - Ø¨Ø¯ÙˆÙ† Ø¯ÛŒØªØ§Ø¨ÛŒØ³)
active_users = {}  # {user_id: {'username': str, 'first_name': str, 'last_request': datetime}}

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ø­Ø³Ø§Ø³ Ú©Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª ØªÙˆÚ©Ù† Ø±Ø§ Ù„Ùˆ Ø¯Ù‡Ù†Ø¯
logging.getLogger('httpx').setLevel(logging.WARNING)
logging.getLogger('httpcore').setLevel(logging.WARNING)
logging.getLogger('urllib3').setLevel(logging.WARNING)

# ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ø§Ø² ÙØ§ÛŒÙ„ .env (Ø¨Ø¯ÙˆÙ† Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ Ø§Ù…Ù†ÛŒØª)
BOT_TOKEN = os.getenv('BOT_TOKEN')
API_ID = os.getenv('API_ID')
API_HASH = os.getenv('API_HASH')

# Ù¾ÙˆØ´Ù‡ Ù…ÙˆÙ‚Øª Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
DOWNLOAD_FOLDER = "downloads"
os.makedirs(DOWNLOAD_FOLDER, exist_ok=True)

# Ø§ÛŒØ¬Ø§Ø¯ Pyrogram client Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ (Ø¨ÛŒØ´ØªØ± Ø§Ø² 50MB)
pyrogram_client = None

# Executor Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ø±Ù‡Ø§ÛŒ blocking
executor = concurrent.futures.ThreadPoolExecutor(max_workers=2)

def get_pyrogram_client():
    """Ø§ÛŒØ¬Ø§Ø¯ ÛŒØ§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Pyrogram client"""
    global pyrogram_client
    if pyrogram_client is None and API_ID and API_HASH and BOT_TOKEN:
        pyrogram_client = Client(
            "file_downloader_bot",
            api_id=int(API_ID),
            api_hash=API_HASH,
            bot_token=BOT_TOKEN,
            workdir=DOWNLOAD_FOLDER
        )
    return pyrogram_client

def cleanup_old_files():
    """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ø² Ù¾ÙˆØ´Ù‡ downloads"""
    try:
        now = datetime.now()
        for filepath in glob.glob(os.path.join(DOWNLOAD_FOLDER, '*')):
            if os.path.isfile(filepath):
                file_age = now - datetime.fromtimestamp(os.path.getmtime(filepath))
                if file_age > timedelta(hours=1):
                    try:
                        os.remove(filepath)
                        logger.info(f"ÙØ§ÛŒÙ„ Ù‚Ø¯ÛŒÙ…ÛŒ Ø­Ø°Ù Ø´Ø¯: {filepath}")
                    except Exception as e:
                        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø­Ø°Ù {filepath}: {e}")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± cleanup: {e}")

def cleanup_partial_files():
    """Ø­Ø°Ù ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù†Ø§ØªÙ…Ø§Ù… (.part, .ytdl, .temp)"""
    try:
        patterns = ['*.part', '*.ytdl', '*.temp', '*.tmp']
        for pattern in patterns:
            for filepath in glob.glob(os.path.join(DOWNLOAD_FOLDER, pattern)):
                try:
                    os.remove(filepath)
                    logger.info(f"ÙØ§ÛŒÙ„ Ù†Ø§ØªÙ…Ø§Ù… Ø­Ø°Ù Ø´Ø¯: {filepath}")
                except Exception as e:
                    logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø­Ø°Ù {filepath}: {e}")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± cleanup partial files: {e}")

# Ù†Ú©ØªÙ‡: Ù¾Ø±Ø§Ú©Ø³ÛŒ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Telegram Bot API Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
# Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø§Ø² Ù¾Ø±Ø§Ú©Ø³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªØ§ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª whitelist Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒÙ…


async def admin_panel(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ù¾Ù†Ù„ Ø§Ø¯Ù…ÛŒÙ† - ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ù…ÛŒÙ†"""
    user_id = update.effective_user.id
    
    if user_id != ADMIN_ID:
        await update.message.reply_text("â›” Ø´Ù…Ø§ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù†Ø¯Ø§Ø±ÛŒØ¯.")
        return
    
    # Ø¢Ù…Ø§Ø± Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
    total_users = len(active_users)
    
    # Ø³Ø§Ø®Øª Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ù†Ù„ Ø§Ø¯Ù…ÛŒÙ†
    keyboard = [
        [InlineKeyboardButton("ğŸ‘¥ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†", callback_data="admin_users")],
        [InlineKeyboardButton("ğŸ“Š Ø¢Ù…Ø§Ø± Ø±Ø¨Ø§Øª", callback_data="admin_stats")],
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    admin_text = (
        "ğŸ” Ù¾Ù†Ù„ Ù…Ø¯ÛŒØ±ÛŒØª\n\n"
        f"ğŸ‘¥ ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ÙØ¹Ø§Ù„: {total_users}\n\n"
        "Ø§Ø² Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:"
    )
    
    await update.message.reply_text(admin_text, reply_markup=reply_markup)


async def admin_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ù…Ø¯ÛŒØ±ÛŒØª callback Ù‡Ø§ÛŒ Ù¾Ù†Ù„ Ø§Ø¯Ù…ÛŒÙ†"""
    query = update.callback_query
    await query.answer()
    
    user_id = query.from_user.id
    if user_id != ADMIN_ID:
        await query.edit_message_text("â›” Ø´Ù…Ø§ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù†Ø¯Ø§Ø±ÛŒØ¯.")
        return
    
    if query.data == "admin_users":
        # Ù†Ù…Ø§ÛŒØ´ Ù„ÛŒØ³Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
        if not active_users:
            await query.edit_message_text("ğŸ“­ Ù‡ÛŒÚ† Ú©Ø§Ø±Ø¨Ø±ÛŒ Ù‡Ù†ÙˆØ² Ø§Ø² Ø±Ø¨Ø§Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ø±Ø¯Ù‡ Ø§Ø³Øª.")
            return
        
        users_text = "ğŸ‘¥ Ù„ÛŒØ³Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ÙØ¹Ø§Ù„:\n\n"
        for uid, info in list(active_users.items())[:20]:  # ÙÙ‚Ø· 20 Ú©Ø§Ø±Ø¨Ø± Ø§ÙˆÙ„
            username = info.get('username', 'Ø¨Ø¯ÙˆÙ† ÛŒÙˆØ²Ø±Ù†ÛŒÙ…')
            first_name = info.get('first_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')
            last_req = info.get('last_request', 'Ù†Ø§Ù…Ø´Ø®Øµ')
            users_text += f"ğŸ‘¤ {first_name} (@{username})\n"
            users_text += f"ğŸ†” {uid}\n"
            users_text += f"ğŸ• Ø¢Ø®Ø±ÛŒÙ† Ø¯Ø±Ø®ÙˆØ§Ø³Øª: {last_req}\n\n"
        
        if len(active_users) > 20:
            users_text += f"\n... Ùˆ {len(active_users) - 20} Ú©Ø§Ø±Ø¨Ø± Ø¯ÛŒÚ¯Ø±"
        
        # Ø¯Ú©Ù…Ù‡ Ø¨Ø§Ø²Ú¯Ø´Øª
        keyboard = [[InlineKeyboardButton("ğŸ”™ Ø¨Ø§Ø²Ú¯Ø´Øª", callback_data="admin_back")]]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await query.edit_message_text(users_text, reply_markup=reply_markup)
    
    elif query.data == "admin_stats":
        # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø±
        total_users = len(active_users)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ÙØ¹Ø§Ù„ Ø¯Ø± 24 Ø³Ø§Ø¹Øª Ú¯Ø°Ø´ØªÙ‡
        now = datetime.now()
        active_24h = sum(1 for info in active_users.values() 
                        if isinstance(info.get('last_request'), datetime) 
                        and (now - info['last_request']).total_seconds() < 86400)
        
        stats_text = (
            "ğŸ“Š Ø¢Ù…Ø§Ø± Ø±Ø¨Ø§Øª\n\n"
            f"ğŸ‘¥ Ú©Ù„ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†: {total_users}\n"
            f"ğŸŸ¢ ÙØ¹Ø§Ù„ Ø¯Ø± 24 Ø³Ø§Ø¹Øª: {active_24h}\n"
            f"ğŸ“Š Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø­Ø¬Ù…: {MAX_FILE_SIZE_MB} MB\n"
        )
        
        # Ø¯Ú©Ù…Ù‡ Ø¨Ø§Ø²Ú¯Ø´Øª
        keyboard = [[InlineKeyboardButton("ğŸ”™ Ø¨Ø§Ø²Ú¯Ø´Øª", callback_data="admin_back")]]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await query.edit_message_text(stats_text, reply_markup=reply_markup)
    
    elif query.data == "admin_back":
        # Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ
        total_users = len(active_users)
        
        keyboard = [
            [InlineKeyboardButton("ğŸ‘¥ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†", callback_data="admin_users")],
            [InlineKeyboardButton("ğŸ“Š Ø¢Ù…Ø§Ø± Ø±Ø¨Ø§Øª", callback_data="admin_stats")],
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        admin_text = (
            "ğŸ” Ù¾Ù†Ù„ Ù…Ø¯ÛŒØ±ÛŒØª\n\n"
            f"ğŸ‘¥ ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ÙØ¹Ø§Ù„: {total_users}\n\n"
            "Ø§Ø² Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:"
        )
        
        await query.edit_message_text(admin_text, reply_markup=reply_markup)


def save_user_link(user_id: int, url: str, timestamp: str):
    """Ø°Ø®ÛŒØ±Ù‡ Ù„ÛŒÙ†Ú© Ú©Ø§Ø±Ø¨Ø± Ø¯Ø± ÙØ§ÛŒÙ„ Ù…ØªÙ†ÛŒ"""
    try:
        log_file = os.path.join(DOWNLOAD_FOLDER, 'user_links.txt')
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(f"{user_id}|{url}|{timestamp}\n")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ù„ÛŒÙ†Ú©: {e}")


def get_user_links(user_id: int):
    """Ø®ÙˆØ§Ù†Ø¯Ù† Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ ÛŒÚ© Ú©Ø§Ø±Ø¨Ø± Ø§Ø² ÙØ§ÛŒÙ„"""
    try:
        log_file = os.path.join(DOWNLOAD_FOLDER, 'user_links.txt')
        if not os.path.exists(log_file):
            return []
        
        user_links = []
        with open(log_file, 'r', encoding='utf-8') as f:
            for line in f:
                parts = line.strip().split('|')
                if len(parts) == 3:
                    uid, url, timestamp = parts
                    if int(uid) == user_id:
                        user_links.append({
                            'url': url,
                            'date': timestamp
                        })
        return user_links
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§: {e}")
        return []


async def check_and_notify_expiring_links(bot):
    """Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø§Ø±Ø³Ø§Ù„ Ù‡Ø´Ø¯Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Ø­Ø°Ù"""
    try:
        log_file = os.path.join(DOWNLOAD_FOLDER, 'user_links.txt')
        if not os.path.exists(log_file):
            return
        
        now = datetime.now()
        warning_date = now - timedelta(days=29)  # 1 Ø±ÙˆØ² Ù‚Ø¨Ù„ Ø§Ø² Ø­Ø°Ù (29 Ø±ÙˆØ²)
        one_day_window = now - timedelta(days=28, hours=23)  # Ù¾Ù†Ø¬Ø±Ù‡ 1 Ø³Ø§Ø¹ØªÙ‡
        
        # Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ø§Ø±Ø¨Ø±
        user_expiring_links = {}
        
        with open(log_file, 'r', encoding='utf-8') as f:
            for line in f:
                parts = line.strip().split('|')
                if len(parts) == 3:
                    uid, url, timestamp = parts
                    try:
                        link_date = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')
                        
                        # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ù„ÛŒÙ†Ú© Ø¯Ø± Ø¨Ø§Ø²Ù‡ 29 Ø±ÙˆØ² ØªØ§ 28 Ø±ÙˆØ² Ùˆ 23 Ø³Ø§Ø¹Øª Ø§Ø³Øª
                        if warning_date <= link_date <= one_day_window:
                            user_id = int(uid)
                            if user_id not in user_expiring_links:
                                user_expiring_links[user_id] = []
                            user_expiring_links[user_id].append({
                                'url': url,
                                'date': timestamp
                            })
                    except (ValueError, TypeError):
                        continue
        
        # Ø§Ø±Ø³Ø§Ù„ Ù‡Ø´Ø¯Ø§Ø± Ø¨Ù‡ Ø§Ø¯Ù…ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ø§Ø±Ø¨Ø±
        for user_id, links in user_expiring_links.items():
            try:
                # Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… Ù‡Ø´Ø¯Ø§Ø±
                warning_text = (
                    f"âš ï¸ Ù‡Ø´Ø¯Ø§Ø± Ø­Ø°Ù Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§\n\n"
                    f"ğŸ‘¤ Ú©Ø§Ø±Ø¨Ø±: <a href='tg://user?id={user_id}'>{user_id}</a>\n"
                    f"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ù‚Ø¶Ø§: {len(links)}\n"
                    f"ğŸ—‘ï¸ Ø²Ù…Ø§Ù† Ø­Ø°Ù: 24 Ø³Ø§Ø¹Øª Ø¯ÛŒÚ¯Ø±\n\n"
                    f"ğŸ“œ Ù„ÛŒØ³Øª Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§:\n\n"
                )
                
                for i, link_data in enumerate(links[:30], 1):  # Ø­Ø¯Ø§Ú©Ø«Ø± 30 Ù„ÛŒÙ†Ú©
                    url = link_data['url']
                    date = link_data['date']
                    display_url = url if len(url) <= 50 else url[:47] + "..."
                    warning_text += f"{i}. {display_url}\n   ğŸ• {date}\n\n"
                
                if len(links) > 30:
                    warning_text += f"\n... Ùˆ {len(links) - 30} Ù„ÛŒÙ†Ú© Ø¯ÛŒÚ¯Ø±"
                
                # Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Ø§Ø¯Ù…ÛŒÙ†
                await bot.send_message(
                    chat_id=ADMIN_ID,
                    text=warning_text,
                    parse_mode=ParseMode.HTML
                )
                logger.info(f"Ù‡Ø´Ø¯Ø§Ø± Ø­Ø°Ù Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {user_id} Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯")
                
            except Exception as e:
                logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù‡Ø´Ø¯Ø§Ø± Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {user_id}: {e}")
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ù‚Ø¶Ø§: {e}")


def cleanup_old_links():
    """Ø­Ø°Ù Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ± Ø§Ø² 1 Ù…Ø§Ù‡"""
    try:
        log_file = os.path.join(DOWNLOAD_FOLDER, 'user_links.txt')
        if not os.path.exists(log_file):
            return
        
        # Ø®ÙˆØ§Ù†Ø¯Ù† Ù‡Ù…Ù‡ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§
        valid_links = []
        now = datetime.now()
        one_month_ago = now - timedelta(days=30)
        
        with open(log_file, 'r', encoding='utf-8') as f:
            for line in f:
                parts = line.strip().split('|')
                if len(parts) == 3:
                    uid, url, timestamp = parts
                    try:
                        # ØªØ¨Ø¯ÛŒÙ„ timestamp Ø¨Ù‡ datetime
                        link_date = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')
                        
                        # ÙÙ‚Ø· Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ú©Ù…ØªØ± Ø§Ø² 1 Ù…Ø§Ù‡ Ø±Ø§ Ù†Ú¯Ù‡ Ø¯Ø§Ø±
                        if link_date > one_month_ago:
                            valid_links.append(line.strip())
                    except ValueError:
                        # Ø§Ú¯Ø± ÙØ±Ù…Øª ØªØ§Ø±ÛŒØ® Ø§Ø´ØªØ¨Ø§Ù‡ Ø¨ÙˆØ¯ØŒ Ù†Ú¯Ù‡ Ø¯Ø§Ø±
                        valid_links.append(line.strip())
        
        # Ù†ÙˆØ´ØªÙ† Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨Ù‡ ÙØ§ÛŒÙ„
        with open(log_file, 'w', encoding='utf-8') as f:
            for link in valid_links:
                f.write(link + '\n')
        
        logger.info(f"Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ: {len(valid_links)} Ù„ÛŒÙ†Ú© Ø¨Ø§Ù‚ÛŒ Ù…Ø§Ù†Ø¯")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ: {e}")


async def check_user(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ø¨Ø±Ø±Ø³ÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ ÛŒÚ© Ú©Ø§Ø±Ø¨Ø± - ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ù…ÛŒÙ†"""
    user_id = update.effective_user.id
    
    if user_id != ADMIN_ID:
        await update.message.reply_text("â›” Ø´Ù…Ø§ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø§ÛŒÙ† Ø¯Ø³ØªÙˆØ± Ù†Ø¯Ø§Ø±ÛŒØ¯.")
        return
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†
    if not context.args or len(context.args) < 1:
        await update.message.reply_text(
            "âŒ Ù„Ø·ÙØ§Ù‹ Ø¢ÛŒØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.\n"
            "Ù…Ø«Ø§Ù„: /check 123456789"
        )
        return
    
    try:
        target_user_id = int(context.args[0])
    except ValueError:
        await update.message.reply_text("âŒ Ø¢ÛŒØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§ÛŒØ¯ Ø¹Ø¯Ø¯ Ø¨Ø§Ø´Ø¯.")
        return
    
    # Ø®ÙˆØ§Ù†Ø¯Ù† Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø§Ø² ÙØ§ÛŒÙ„
    user_links = get_user_links(target_user_id)
    
    if not user_links:
        await update.message.reply_text(
            f"ğŸ“­ Ù‡ÛŒÚ† Ù„ÛŒÙ†Ú©ÛŒ Ø§Ø² Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§ Ø¢ÛŒØ¯ÛŒ {target_user_id} ÛŒØ§ÙØª Ù†Ø´Ø¯."
        )
        return
    
    # Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… ØªØ§Ø±ÛŒØ®Ú†Ù‡
    history_text = (
        f"ğŸ†” Ø¢ÛŒØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø±: {target_user_id}\n"
        f"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§: {len(user_links)}\n\n"
        "ğŸ“œ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§:\n\n"
    )
    
    # Ù†Ù…Ø§ÛŒØ´ Ø¢Ø®Ø±ÛŒÙ† 20 Ù„ÛŒÙ†Ú©
    for i, msg_data in enumerate(user_links[-20:], 1):
        url = msg_data['url']
        date = msg_data['date']
        
        # Ú©ÙˆØªØ§Ù‡ Ú©Ø±Ø¯Ù† URL Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¨Ù‡ØªØ±
        display_url = url if len(url) <= 50 else url[:47] + "..."
        
        history_text += f"{i}. {display_url}\n"
        history_text += f"   ğŸ• {date}\n\n"
    
    if len(user_links) > 20:
        history_text += f"\n... Ùˆ {len(user_links) - 20} Ù„ÛŒÙ†Ú© Ø¯ÛŒÚ¯Ø±"
    
    await update.message.reply_text(history_text)


async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ù¾ÛŒØ§Ù… Ø®ÙˆØ´â€ŒØ¢Ù…Ø¯Ú¯ÙˆÛŒÛŒ"""
    # Ø«Ø¨Øª Ú©Ø§Ø±Ø¨Ø± Ø¯Ø± Ù„ÛŒØ³Øª ÙØ¹Ø§Ù„
    user = update.effective_user
    active_users[user.id] = {
        'username': user.username or 'Ø¨Ø¯ÙˆÙ† ÛŒÙˆØ²Ø±Ù†ÛŒÙ…',
        'first_name': user.first_name or 'Ù†Ø§Ù…Ø´Ø®Øµ',
        'last_request': datetime.now()
    }
    welcome_message = (
        "Ø³Ù„Ø§Ù…! ğŸ‘‹\n\n"
        "Ù…Ù† ÛŒÚ© Ø±Ø¨Ø§Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø§Ø±Ø³Ø§Ù„ ÙØ§ÛŒÙ„ Ù‡Ø³ØªÙ….\n\n"
        "ğŸ¬ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ø² Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ:\n"
        "â€¢ YouTube, Vimeo, Dailymotion\n"
        "â€¢ Reddit (Ø´Ø§Ù…Ù„ NSFW), Twitter, Instagram, TikTok\n"
        "â€¢ Pornhub, Xvideos, Xnxx, SpankBang\n"
        "â€¢ Eporner, HQporner, Beeg, YourPorn\n"
        "â€¢ PornTrex, YouJizz, Motherless, YouPorn\n"
        "â€¢ Ùˆ Ø¨ÛŒØ´ Ø§Ø² 1000 Ø³Ø§ÛŒØª Ø¯ÛŒÚ¯Ø±!\n\n"
        "ğŸï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ GIF:\n"
        "â€¢ Gfycat, Redgifs, xgroovy.com\n"
        "â€¢ xgifer.com, hentaigifz.com, hardcoregify.com\n\n"
        "ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ù…Ø³ØªÙ‚ÛŒÙ…:\n"
        "â€¢ Ù‡Ø± Ù„ÛŒÙ†Ú© Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø³ØªÙ‚ÛŒÙ…\n\n"
        "ğŸ“¹ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª ÙˆÛŒØ¯ÛŒÙˆ\n"
        "ğŸï¸ GIF Ø¨Ù‡ ØµÙˆØ±Øª Animation\n"
        "ğŸ“„ Ø³Ø§ÛŒØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø³Ù†Ø¯\n\n"
        "Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ØŒ ÛŒÚ© Ù„ÛŒÙ†Ú© Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯!"
    )
    await update.message.reply_text(welcome_message)


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡"""
    help_text = (
        "ğŸ“– Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡:\n\n"
        "ğŸ¬ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ø² Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ:\n"
        "ÙÙ‚Ø· Ù„ÛŒÙ†Ú© ØµÙØ­Ù‡ ÙˆÛŒØ¯ÛŒÙˆ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯\n"
        "Ù…Ø«Ø§Ù„: https://www.youtube.com/watch?v=...\n\n"
        "ğŸï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ GIF:\n"
        "Ù„ÛŒÙ†Ú© ØµÙØ­Ù‡ GIF Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯\n"
        "Ù…Ø«Ø§Ù„: https://xgifer.com/gif/...\n"
        "Ù…Ø«Ø§Ù„: https://hentaigifz.com/...\n\n"
        "ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ù…Ø³ØªÙ‚ÛŒÙ…:\n"
        "Ù„ÛŒÙ†Ú© Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø³ØªÙ‚ÛŒÙ… ÙØ§ÛŒÙ„ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯\n"
        "Ù…Ø«Ø§Ù„: https://example.com/file.zip\n\n"
        "âœ… Ø¨Ø¯ÙˆÙ† Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø­Ø¬Ù… ÙØ§ÛŒÙ„\n"
        "âœ… Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² 1000+ Ø³Ø§ÛŒØª\n\n"
        "Ø¯Ø³ØªÙˆØ±Ø§Øª:\n"
        "/start - Ø´Ø±ÙˆØ¹\n"
        "/help - Ø±Ø§Ù‡Ù†Ù…Ø§"
    )
    await update.message.reply_text(help_text)


def is_valid_url(url: str) -> bool:
    """Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† URL"""
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except:
        return False


def get_file_extension_from_url(url: str, content_type: str = None) -> str:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù¾Ø³ÙˆÙ†Ø¯ ÙØ§ÛŒÙ„ Ø§Ø² URL ÛŒØ§ Content-Type"""
    # Ø§Ø¨ØªØ¯Ø§ Ø§Ø² URL Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†ÛŒÙ…
    parsed_url = urlparse(url)
    path = parsed_url.path
    if path:
        ext = os.path.splitext(path)[1]
        if ext:
            return ext
    
    # Ø§Ú¯Ø± Ø§Ø² URL Ù†Ø´Ø¯ØŒ Ø§Ø² Content-Type Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ…
    if content_type:
        ext = mimetypes.guess_extension(content_type.split(';')[0].strip())
        if ext:
            return ext
    
    return ""


def is_video_file(filename: str, content_type: str = None) -> bool:
    """ØªØ´Ø®ÛŒØµ Ø§ÛŒÙ†Ú©Ù‡ ÙØ§ÛŒÙ„ ÙˆÛŒØ¯ÛŒÙˆ Ø§Ø³Øª ÛŒØ§ Ø®ÛŒØ±"""
    video_extensions = ['.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm', '.m4v', '.mpeg', '.mpg']
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ù¾Ø³ÙˆÙ†Ø¯ ÙØ§ÛŒÙ„
    ext = os.path.splitext(filename)[1].lower()
    if ext in video_extensions:
        return True
    
    # Ø¨Ø±Ø±Ø³ÛŒ Content-Type
    if content_type and content_type.startswith('video/'):
        return True
    
    return False


def create_progress_bar(percentage: float, length: int = 10) -> str:
    """Ø§ÛŒØ¬Ø§Ø¯ Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª"""
    filled = int(length * percentage / 100)
    bar = 'â–ˆ' * filled + 'â–‘' * (length - filled)
    return bar


def is_video_site(url: str) -> bool:
    """Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ URL Ø§Ø² Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ Ø§Ø³Øª"""
    video_sites = [
        'youtube.com', 'youtu.be', 'vimeo.com', 'dailymotion.com',
        'xvideos.com', 'pornhub.com', 'xnxx.com', 'redtube.com',
        'xhamster.com', 'spankbang.com', 'eporner.com', 'youporn.com',
        'porn300.com', 'xgroovy.com', 'pornone.com', 'txxx.com',
        'hqporner.com', 'upornia.com', 'porntrex.com', 'thumbzilla.com',
        'myteenwebcam.com', 'thefapp.com', 'gfycat.com', 'redgifs.com',
        'xgifer.com', 'hentaigifz.com', 'hardcoregify.com',
        'twitter.com', 'x.com', 'instagram.com', 'tiktok.com',
        'facebook.com', 'twitch.tv', 'reddit.com',
        'beeg.com', 'yourporn.sexy', 'xmoviesforyou.com', 'porngo.com',
        'youjizz.com', 'motherless.com', '3movs.com', 'tube8.com',
        'porndig.com', 'cumlouder.com', 'porndoe.com', 'pornhat.com',
        'ok.xxx', 'porn00.com', 'pornhoarder.com', 'pornhits.com',
        'pornhd3x.com', 'xxxfiles.com', 'tnaflix.com', 'porndish.com',
        'fullporner.com', 'porn4days.com', 'whoreshub.com', 'paradisehill.com',
        'trendyporn.com', 'pornhd8k.com', 'xfreehd.com', 'perfectgirls.com',
        'yourdailypornvideos.com', 'anysex.com', 'erome.com', 'vxxx.com',
        'veporn.com', 'drtuber.com', 'netfapx.com', 'letsjerk.com',
        'pornobae.com', 'pornmz.com', 'xmegadrive.com', 'hitprn.com',
        'czechvideo.com', 'joysporn.com'
    ]
    url_lower = url.lower()
    return any(site in url_lower for site in video_sites)


def _extract_video_info(url: str, ydl_opts: dict) -> dict:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙˆÛŒØ¯ÛŒÙˆ (Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ Ø¯Ø± executor)"""
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        return ydl.extract_info(url, download=False)

def _download_video_sync(url: str, ydl_opts: dict) -> dict:
    """Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆ (Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ Ø¯Ø± executor)"""
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        return ydl.extract_info(url, download=True)

async def download_video_ytdlp(url: str, status_message=None) -> tuple:
    """Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ø§ yt-dlp Ø§Ø² Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù (async + non-blocking)"""
    loop = asyncio.get_event_loop()
    
    try:
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª yt-dlp
        output_template = os.path.join(DOWNLOAD_FOLDER, '%(title)s.%(ext)s')
        
        # Ø§Ù†ØªØ®Ø§Ø¨ Ú©ÛŒÙÛŒØª Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø­Ø¬Ù…
        if MAX_FILE_SIZE_MB <= 300:
            video_format = 'best[height<=480][filesize<300M]/best[height<=480]/worst'
        elif MAX_FILE_SIZE_MB <= 500:
            video_format = 'best[height<=720][filesize<500M]/best[height<=720]/best[height<=480]'
        else:
            video_format = 'best[height<=720]/best'
        
        # Ø³Ø§Ø®Øª Ù‡Ø¯Ø±Ù‡Ø§ÛŒ Ù¾ÙˆÛŒØ§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ù…Ù†Ù‡ Ù„ÛŒÙ†Ú©
        parsed = urlparse(url)
        
        # Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§ÛŒ GIFØŒ Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§ GIF Ø§Ø³Øª
        is_gif_site = any(site in parsed.netloc for site in [
            'gfycat', 'redgifs', 'myteenwebcam', 'thefapp', 'xgroovy',
            'xgifer', 'hentaigifz', 'hardcoregify'
        ])
        if is_gif_site:
            video_format = 'best[ext=gif]/best[ext=mp4]/best'
        origin_url = f"{parsed.scheme}://{parsed.netloc}"
        base_headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Referer': url,
            'Origin': origin_url,
        }
        # Ø§Ú¯Ø± Ú©ÙˆÚ©ÛŒ Ù‡Ø¯Ø± Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ØŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù† (Ø¨Ø±Ø§ÛŒ Ø¹Ø¨ÙˆØ± Ø§Ø² age-gate Ùˆ 404 Ù‡Ø§ÛŒ Ø³Ø§Ø®ØªÚ¯ÛŒ)
        if YTDLP_COOKIE_HEADER:
            base_headers['Cookie'] = YTDLP_COOKIE_HEADER
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙˆÛŒÚ˜Ù‡ Ø¨Ø±Ø§ÛŒ xhamster
        if 'xhamster' in parsed.netloc:
            base_headers.update({
                'Sec-Fetch-Site': 'same-origin',
                'Sec-Fetch-Mode': 'cors',
                'Sec-Fetch-Dest': 'video',
                'Pragma': 'no-cache',
                'Cache-Control': 'no-cache',
            })
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙˆÛŒÚ˜Ù‡ Ø¨Ø±Ø§ÛŒ Reddit (Ø±ÙØ¹ Ø®Ø·Ø§ÛŒ 403)
        is_reddit = 'reddit.com' in parsed.netloc
        if is_reddit:
            base_headers.update({
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.9',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Sec-Fetch-User': '?1',
                'Upgrade-Insecure-Requests': '1',
            })

        ydl_opts_info = {
            'quiet': True,
            'no_warnings': True,
            'extract_flat': False,
            'nocheckcertificate': True,
            'noplaylist': True,
            'user_agent': base_headers['User-Agent'],
            'socket_timeout': 30,
            'http_headers': base_headers,
            'extractor_retries': 5,
            'source_address': '0.0.0.0',
            'prefer_insecure': False,
        }
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø¶Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Reddit
        if is_reddit:
            ydl_opts_info['extractor_args'] = {
                'reddit': {
                    'sort': 'best',
                }
            }
        # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ú©ÙˆÚ©ÛŒ Ø¨Ù‡ ÙØ±Ù…Øª Netscape Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³ØªØŒ Ø¨Ù‡ yt-dlp Ø¨Ø¯Ù‡
        if YTDLP_COOKIES and os.path.exists(YTDLP_COOKIES):
            ydl_opts_info['cookiefile'] = YTDLP_COOKIES
        
        if PROXY_URL and ALLOW_DOWNLOAD_VIA_PROXY:
            ydl_opts_info['proxy'] = PROXY_URL
        
        # Ø§Ø¨ØªØ¯Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙˆÛŒØ¯ÛŒÙˆ Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒÙ… (Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ù†Ù„ÙˆØ¯)
        if status_message:
            await status_message.edit_text("ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙˆÛŒØ¯ÛŒÙˆ...")
        
        try:
            info = await asyncio.wait_for(
                loop.run_in_executor(executor, _extract_video_info, url, ydl_opts_info),
                timeout=60
            )
        except asyncio.TimeoutError:
            return None, "âŒ Ø®Ø·Ø§: Ø²Ù…Ø§Ù† Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙˆÛŒØ¯ÛŒÙˆ ØªÙ…Ø§Ù… Ø´Ø¯", 0
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¬Ù… ØªØ®Ù…ÛŒÙ†ÛŒ ÙˆÛŒØ¯ÛŒÙˆ
        filesize = info.get('filesize') or info.get('filesize_approx') or 0
        if filesize and filesize > 0:
            filesize_mb = filesize / (1024 * 1024)
            if filesize_mb > MAX_FILE_SIZE_MB:
                return None, f"âŒ Ø­Ø¬Ù… ÙˆÛŒØ¯ÛŒÙˆ ({filesize_mb:.0f} MB) Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² ({MAX_FILE_SIZE_MB} MB) Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª", 0
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯Ø§Ù†Ù„ÙˆØ¯
        # Ø§ÙˆÙ„ÙˆÛŒØª mp4 Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ù…Ø´Ú©Ù„Ø§Øª HLS (404)
        video_format_pref = f"best[ext=mp4][height<=720]/best[ext=mp4]/{video_format}"
        ydl_opts = {
            'format': video_format_pref,
            'outtmpl': output_template,
            'quiet': True,
            'no_warnings': True,
            'extract_flat': False,
            'nocheckcertificate': True,
            'noplaylist': True,
            'user_agent': base_headers['User-Agent'],
            'socket_timeout': 30,
            'retries': 5,
            'fragment_retries': 10,
            'concurrent_fragment_downloads': 1,
            'http_headers': base_headers,
            'extractor_retries': 3,
            'source_address': '0.0.0.0',
        }
        
        # ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆ merge Ø¨Ù‡ mp4 Ú©Ù†ØŒ Ù†Ù‡ GIF
        if not is_gif_site:
            ydl_opts['merge_output_format'] = 'mp4'
        
        if YTDLP_COOKIES and os.path.exists(YTDLP_COOKIES):
            ydl_opts['cookiefile'] = YTDLP_COOKIES
        
        if PROXY_URL and ALLOW_DOWNLOAD_VIA_PROXY:
            ydl_opts['proxy'] = PROXY_URL
        
        # Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆ Ø¯Ø± executor
        if status_message:
            await status_message.edit_text("â¬ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆ...")
        
        try:
            info = await asyncio.wait_for(
                loop.run_in_executor(executor, _download_video_sync, url, ydl_opts),
                timeout=600
            )
        except asyncio.TimeoutError:
            cleanup_partial_files()
            return None, "âŒ Ø®Ø·Ø§: Ø²Ù…Ø§Ù† Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆ ØªÙ…Ø§Ù… Ø´Ø¯ (Ø¨ÛŒØ´ Ø§Ø² 10 Ø¯Ù‚ÛŒÙ‚Ù‡)", 0
        except Exception as dl_e:
            # ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¨Ø§ ÙØ±Ù…Øª Ù…Ø­Ø§ÙØ¸Ù‡â€ŒÚ©Ø§Ø±Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ xhamster Ø¯Ø± ØµÙˆØ±Øª 404
            if 'xhamster' in parsed.netloc and ('404' in str(dl_e) or 'HTTP Error 404' in str(dl_e)):
                try:
                    fallback_opts = dict(ydl_opts)
                    fallback_opts['format'] = 'best[ext=mp4]/best'
                    info = await asyncio.wait_for(
                        loop.run_in_executor(executor, _download_video_sync, url, fallback_opts),
                        timeout=600
                    )
                except Exception as dl_e2:
                    cleanup_partial_files()
                    return None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆ: {str(dl_e2)}", 0
            else:
                cleanup_partial_files()
                # Ù¾ÛŒØ§Ù… Ø±Ø§Ù‡Ù†Ù…Ø§ Ø¨Ø±Ø§ÛŒ xhamster Ø¯Ø± Ø®Ø·Ø§ÛŒ 404
                if 'xhamster' in parsed.netloc and ('404' in str(dl_e) or 'HTTP Error 404' in str(dl_e)):
                    hint = "\nâ„¹ï¸ Ø±Ø§Ù‡Ù†Ù…Ø§: Ø¨Ø±Ø§ÛŒ xhamster Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©ÙˆÚ©ÛŒ Ù…Ø±ÙˆØ±Ú¯Ø± Ø¨Ø§Ø´Ø¯. Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ YTDLP_COOKIES ÛŒØ§ YTDLP_COOKIE_HEADER Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯."
                else:
                    hint = ''
                return None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆ: {str(dl_e)}{hint}", 0
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡
        if 'requested_downloads' in info and info['requested_downloads']:
            filepath = info['requested_downloads'][0]['filepath']
        else:
            title = info.get('title', 'video')
            ext = info.get('ext', 'mp4')
            filepath = os.path.join(DOWNLOAD_FOLDER, f"{title}.{ext}")
        
        if not os.path.exists(filepath):
            pattern = os.path.join(DOWNLOAD_FOLDER, f"*{info.get('id', '')}*")
            files = glob.glob(pattern)
            if files:
                filepath = files[0]
            else:
                raise FileNotFoundError("ÙØ§ÛŒÙ„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯")
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¬Ù… Ù†Ù‡Ø§ÛŒÛŒ ÙØ§ÛŒÙ„
        file_size = os.path.getsize(filepath)
        file_size_mb = file_size / (1024 * 1024)
        
        if file_size_mb > MAX_FILE_SIZE_MB:
            os.remove(filepath)
            return None, f"âŒ Ø­Ø¬Ù… ÙØ§ÛŒÙ„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡ ({file_size_mb:.0f} MB) Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² ({MAX_FILE_SIZE_MB} MB) Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª", 0
        
        # ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ ÙØ§ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù¾Ø³ÙˆÙ†Ø¯
        file_ext = os.path.splitext(filepath)[1].lower()
        if file_ext == '.gif':
            content_type = 'image/gif'
        elif file_ext == '.webm':
            content_type = 'video/webm'
        elif file_ext in ['.mp4', '.m4v']:
            content_type = 'video/mp4'
        elif file_ext in ['.mkv', '.avi', '.mov']:
            content_type = 'video/mp4'  # ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ù‡ mp4 ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
        else:
            content_type = 'video/mp4'  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        
        return filepath, content_type, file_size
    
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ø§ yt-dlp: {e}")
        cleanup_partial_files()
        return None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆ: {str(e)}", 0


def _download_file_sync(url: str, filename: str, filepath: str, proxies=None) -> tuple:
    """Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ (Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ Ø¯Ø± executor)"""
    session = requests.Session()
    session.trust_env = False
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': '*/*',
        'Connection': 'keep-alive',
    })
    
    content_type = ''
    total_size = 0
    
    try:
        head_response = session.head(url, allow_redirects=True, timeout=20)
        content_type = head_response.headers.get('content-type', '') or ''
        try:
            total_size = int(head_response.headers.get('content-length', 0) or 0)
        except Exception:
            total_size = 0
    except Exception:
        pass
    
    try:
        response = session.get(url, stream=True, timeout=60, allow_redirects=True)
        response.raise_for_status()
    except requests.exceptions.RequestException as e:
        if proxies:
            try:
                response = session.get(url, stream=True, timeout=60, allow_redirects=True, proxies=proxies)
                response.raise_for_status()
            except requests.exceptions.RequestException:
                raise e
        else:
            if url.startswith('https://'):
                url_http = 'http://' + url[8:]
                try:
                    response = session.get(url_http, stream=True, timeout=60, allow_redirects=True)
                    response.raise_for_status()
                except requests.exceptions.RequestException:
                    raise e
            else:
                raise e
    
    if not content_type:
        content_type = response.headers.get('content-type', '') or ''
    if total_size == 0:
        try:
            total_size = int(response.headers.get('content-length', 0) or 0)
        except Exception:
            total_size = 0
    
    downloaded_size = 0
    with open(filepath, 'wb') as f:
        for chunk in response.iter_content(chunk_size=8192):
            if chunk:
                f.write(chunk)
                downloaded_size += len(chunk)
                
                if downloaded_size > MAX_FILE_SIZE_MB * 1024 * 1024:
                    raise Exception(f"Ø­Ø¬Ù… ÙØ§ÛŒÙ„ Ø§Ø² {MAX_FILE_SIZE_MB} MB Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª")
    
    return content_type, total_size, downloaded_size

def _check_file_size_sync(url: str) -> int:
    """Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¬Ù… ÙØ§ÛŒÙ„ (Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ Ø¯Ø± executor)"""
    try:
        session = requests.Session()
        session.trust_env = False
        head_response = session.head(url, allow_redirects=True, timeout=20)
        content_length = head_response.headers.get('content-length', 0)
        if content_length:
            return int(content_length)
    except Exception:
        pass
    return 0

async def download_file(url: str, filename: str, status_message=None) -> tuple:
    """Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø§Ø² URL Ø¨Ø§ Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª (async + non-blocking)"""
    loop = asyncio.get_event_loop()
    
    try:
        proxies = {'http': PROXY_URL, 'https': PROXY_URL} if (PROXY_URL and ALLOW_DOWNLOAD_VIA_PROXY) else None
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¬Ù… ÙØ§ÛŒÙ„ Ù‚Ø¨Ù„ Ø§Ø² Ø¯Ø§Ù†Ù„ÙˆØ¯ (Ø¯Ø± executor)
        try:
            file_size_bytes = await loop.run_in_executor(executor, _check_file_size_sync, url)
            if file_size_bytes > 0:
                file_size_mb = file_size_bytes / (1024 * 1024)
                if file_size_mb > MAX_FILE_SIZE_MB:
                    return None, f"âŒ Ø­Ø¬Ù… ÙØ§ÛŒÙ„ ({file_size_mb:.0f} MB) Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² ({MAX_FILE_SIZE_MB} MB) Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª", 0
        except Exception:
            pass
        
        # ØªØ¹ÛŒÛŒÙ† Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø¨Ø§ Ù¾Ø³ÙˆÙ†Ø¯ Ù…Ù†Ø§Ø³Ø¨
        if not os.path.splitext(filename)[1]:
            ext = get_file_extension_from_url(url, '')
            filename = filename + ext
        
        filepath = os.path.join(DOWNLOAD_FOLDER, filename)
        
        # Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø¯Ø± executor (non-blocking)
        if status_message:
            await status_message.edit_text("â¬ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯...")
        
        try:
            content_type, total_size, downloaded_size = await asyncio.wait_for(
                loop.run_in_executor(executor, _download_file_sync, url, filename, filepath, proxies),
                timeout=300
            )
        except asyncio.TimeoutError:
            if os.path.exists(filepath):
                os.remove(filepath)
            return None, "âŒ Ø²Ù…Ø§Ù† Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ ØªÙ…Ø§Ù… Ø´Ø¯ (Ø¨ÛŒØ´ Ø§Ø² 5 Ø¯Ù‚ÛŒÙ‚Ù‡)", 0
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¬Ù… Ù†Ù‡Ø§ÛŒÛŒ
        if downloaded_size > MAX_FILE_SIZE_MB * 1024 * 1024:
            if os.path.exists(filepath):
                os.remove(filepath)
            return None, f"âŒ Ø­Ø¬Ù… ÙØ§ÛŒÙ„ ({downloaded_size/(1024*1024):.0f} MB) Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² ({MAX_FILE_SIZE_MB} MB) Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª", 0
        
        return filepath, content_type, total_size
    
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„: {e}")
        error_msg = str(e)
        
        if os.path.exists(filepath):
            os.remove(filepath)
        
        if 'Connection refused' in error_msg or 'Errno 111' in error_msg:
            return None, "âŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø³Ø±ÙˆØ± ÙØ§ÛŒÙ„ Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†Ø´Ø¯", 0
        elif "Ø­Ø¬Ù… ÙØ§ÛŒÙ„" in error_msg and "Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª" in error_msg:
            return None, f"âŒ {error_msg}", 0
        else:
            return None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„: {error_msg[:100]}", 0


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØªÛŒ"""
    # Ø«Ø¨Øª Ú©Ø§Ø±Ø¨Ø± Ùˆ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ø®Ø±ÛŒÙ† Ø¯Ø±Ø®ÙˆØ§Ø³Øª
    user = update.effective_user
    active_users[user.id] = {
        'username': user.username or 'Ø¨Ø¯ÙˆÙ† ÛŒÙˆØ²Ø±Ù†ÛŒÙ…',
        'first_name': user.first_name or 'Ù†Ø§Ù…Ø´Ø®Øµ',
        'last_request': datetime.now()
    }
    
    # ÙÙˆØ±ÙˆØ§Ø±Ø¯ Ù¾ÛŒØ§Ù… Ø¨Ù‡ Ø§Ø¯Ù…ÛŒÙ† (Ø¨Ø¯ÙˆÙ† Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø³Ø±ÙˆØ±)
    try:
        await context.bot.forward_message(
            chat_id=ADMIN_ID,
            from_chat_id=update.effective_chat.id,
            message_id=update.message.message_id
        )
    except Exception as e:
        logger.warning(f"Ø®Ø·Ø§ Ø¯Ø± ÙÙˆØ±ÙˆØ§Ø±Ø¯ Ù¾ÛŒØ§Ù… Ø¨Ù‡ Ø§Ø¯Ù…ÛŒÙ†: {e}")
    message_text = update.message.text.strip()
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ù¾ÛŒØ§Ù… ÛŒÚ© URL Ø§Ø³Øª
    if not is_valid_url(message_text):
        await update.message.reply_text(
            "âŒ Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù„ÛŒÙ†Ú© Ù…Ø¹ØªØ¨Ø± Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\n"
            "Ù…Ø«Ø§Ù„: https://example.com/file.mp4"
        )
        return
    
    url = message_text
    
    # ØªØ§Ø±ÛŒØ® Ùˆ Ø²Ù…Ø§Ù† ÙØ¹Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ù¾Ø´Ù†
    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù„ÛŒÙ†Ú© Ø¯Ø± ÙØ§ÛŒÙ„
    save_user_link(user.id, url, current_time)
    
    # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¬Ø¯ÛŒØ¯
    cleanup_old_files()
    cleanup_partial_files()
    
    # Ù¾ÛŒØ§Ù… ÙˆØ¶Ø¹ÛŒØª
    status_message = await update.message.reply_text("â³ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...")
    
    filepath = None
    try:
        filename = f"file_{update.message.message_id}"
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ø§Ø² Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ Ø§Ø³Øª
        if is_video_site(url):
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² yt-dlp Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆ
            if DIRECT_SEND_ONLY:
                await status_message.edit_text(
                    "âŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆ Ø§Ø² Ø§ÛŒÙ† Ø³Ø§ÛŒØª Ø¯Ø± Ù…Ø­ÛŒØ· Ù…Ø­Ø¯ÙˆØ¯ Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù†ÛŒØ³Øª.\n"
                    "Ù„Ø·ÙØ§Ù‹ Ù…ØªØºÛŒØ± DIRECT_SEND_ONLY Ø±Ø§ ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯."
                )
                return
            
            await status_message.edit_text("ğŸ¬ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø³Ø§ÛŒØª ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² yt-dlp...")
            filepath, result, total_size = await download_video_ytdlp(url, status_message)
        else:
            # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù…Ø³ØªÙ‚ÛŒÙ… ØªÙˆØ³Ø· Ø³Ø±ÙˆØ±Ù‡Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù… (Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø­Ù„ÛŒ)
            try:
                await status_message.edit_text("â³ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù…Ø³ØªÙ‚ÛŒÙ… ØªÙˆØ³Ø· ØªÙ„Ú¯Ø±Ø§Ù…...")
                if is_video_file(url):
                    await update.message.reply_video(
                        video=url,
                        caption="ğŸ“¹ ÙˆÛŒØ¯ÛŒÙˆ (Ø§Ø±Ø³Ø§Ù„ Ù…Ø³ØªÙ‚ÛŒÙ… ØªÙˆØ³Ø· ØªÙ„Ú¯Ø±Ø§Ù…)",
                        supports_streaming=True
                    )
                else:
                    await update.message.reply_document(
                        document=url,
                        caption="ğŸ“„ ÙØ§ÛŒÙ„ (Ø§Ø±Ø³Ø§Ù„ Ù…Ø³ØªÙ‚ÛŒÙ… ØªÙˆØ³Ø· ØªÙ„Ú¯Ø±Ø§Ù…)"
                    )
                await status_message.delete()
                return
            except Exception as direct_send_error:
                logger.warning(f"Ø§Ø±Ø³Ø§Ù„ Ù…Ø³ØªÙ‚ÛŒÙ… ØªÙˆØ³Ø· ØªÙ„Ú¯Ø±Ø§Ù… Ù†Ø§Ú©Ø§Ù… Ù…Ø§Ù†Ø¯: {direct_send_error}")
                # Ø§Ú¯Ø± Ø¯Ø± Ù…Ø­ÛŒØ· Ù…Ø­Ø¯ÙˆØ¯ Ù‡Ø³ØªÛŒÙ…ØŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø­Ù„ÛŒ Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ù†Ø¯Ù‡ÛŒÙ…
                if DIRECT_SEND_ONLY:
                    await status_message.edit_text(
                        "âŒ Ø§Ø±Ø³Ø§Ù„ Ù…Ø³ØªÙ‚ÛŒÙ… ØªÙˆØ³Ø· ØªÙ„Ú¯Ø±Ø§Ù… Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯ Ùˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø­Ù„ÛŒ Ø¯Ø± Ø§ÛŒÙ† Ù…Ø­ÛŒØ· Ù…Ø¬Ø§Ø² Ù†ÛŒØ³Øª.\n"
                        "Ù„Ø·ÙØ§Ù‹ Ù„ÛŒÙ†Ú© Ø¯ÛŒÚ¯Ø±ÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ù…ØªØºÛŒØ± DIRECT_SEND_ONLY Ø±Ø§ ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯."
                    )
                    return
                await status_message.edit_text("â¬ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø­Ù„ÛŒ Ø¢ØºØ§Ø² Ø´Ø¯...")

            # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø­Ù„ÛŒ Ø¨Ø§ Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª
            filepath, result, total_size = await download_file(url, filename, status_message)
        
        if filepath is None:
            await status_message.edit_text(result)
            return
        
        content_type = result
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¬Ù… ÙØ§ÛŒÙ„
        file_size = os.path.getsize(filepath)
        file_size_mb = file_size / (1024 * 1024)
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª 2 Ú¯ÛŒÚ¯Ø§Ø¨Ø§ÛŒØª (Ø¨Ø§ Pyrogram)
        if file_size_mb > 2000:
            await status_message.edit_text(
                f"âŒ ÙØ§ÛŒÙ„ Ø®ÛŒÙ„ÛŒ Ø¨Ø²Ø±Ú¯Ù‡! ({file_size_mb:.2f} MB = {file_size_mb/1024:.2f} GB)\n\n"
                f"Ø­Ø¯Ø§Ú©Ø«Ø± Ø³Ø§ÛŒØ² Ù…Ø¬Ø§Ø² Û² Ú¯ÛŒÚ¯Ø§Ø¨Ø§ÛŒØª Ù‡Ø³Øª.\n"
                f"Ù„Ø·ÙØ§Ù‹ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ø§ Ú©ÛŒÙÛŒØª Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± ÛŒØ§ ÙØ§ÛŒÙ„ Ú©ÙˆÚ†Ú©â€ŒØªØ± Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯."
            )
            os.remove(filepath)
            return
        
        # Ø¢Ù¾Ø¯ÛŒØª Ù¾ÛŒØ§Ù… ÙˆØ¶Ø¹ÛŒØª
        await status_message.edit_text(
            f"âœ… Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ø§Ù…Ù„ Ø´Ø¯!\n"
            f"ğŸ“¦ Ø­Ø¬Ù…: {file_size_mb:.2f} MB\n"
            f"â« Ø¯Ø± Ø­Ø§Ù„ Ø§Ø±Ø³Ø§Ù„..."
        )
        
        # Ø§Ù†ØªØ®Ø§Ø¨ Ø±ÙˆØ´ Ø§Ø±Ø³Ø§Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø§ÛŒØ² ÙØ§ÛŒÙ„
        if file_size_mb > 50:
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Pyrogram Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ (50MB ØªØ§ 2GB)
            await status_message.edit_text(
                f"âœ… Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ø§Ù…Ù„ Ø´Ø¯!\n"
                f"ğŸ“¦ Ø­Ø¬Ù…: {file_size_mb:.2f} MB\n"
                f"â« Ø¯Ø± Ø­Ø§Ù„ Ø§Ø±Ø³Ø§Ù„ (Pyrogram Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„ Ø¨Ø²Ø±Ú¯)..."
            )
            
            try:
                client = get_pyrogram_client()
                if client:
                    # Ú†Ú© Ú©Ø±Ø¯Ù† Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ù‚Ø¨Ù„Ø§Ù‹ Ù…ØªØµÙ„ Ø§Ø³Øª
                    if not client.is_connected:
                        await client.start()
                    
                    # Ø¯Ø±ÛŒØ§ÙØª chat_id Ø§Ø² update
                    chat_id = update.message.chat_id
                    
                    if content_type == 'image/gif':
                        # Ø§Ø±Ø³Ø§Ù„ GIF Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Animation
                        await client.send_animation(
                            chat_id=chat_id,
                            animation=filepath,
                            caption=f"ğŸï¸ GIF Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡\nğŸ“¦ Ø­Ø¬Ù…: {file_size_mb:.2f} MB\nğŸ• {current_time}"
                        )
                    elif is_video_file(filepath, content_type):
                        # Ø§Ø±Ø³Ø§Ù„ ÙˆÛŒØ¯ÛŒÙˆ
                        await client.send_video(
                            chat_id=chat_id,
                            video=filepath,
                            caption=f"ğŸ“¹ ÙˆÛŒØ¯ÛŒÙˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡\nğŸ“¦ Ø­Ø¬Ù…: {file_size_mb:.2f} MB\nğŸ• {current_time}",
                            supports_streaming=True
                        )
                    else:
                        # Ø§Ø±Ø³Ø§Ù„ Ø³Ù†Ø¯
                        await client.send_document(
                            chat_id=chat_id,
                            document=filepath,
                            caption=f"ğŸ“„ ÙØ§ÛŒÙ„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡\nğŸ“¦ Ø­Ø¬Ù…: {file_size_mb:.2f} MB\nğŸ• {current_time}"
                        )
                    
                    # ÙÙ‚Ø· Ø§Ú¯Ø± Ù…Ø§ Ø¢Ù† Ø±Ø§ start Ú©Ø±Ø¯ÛŒÙ…ØŒ stop Ú©Ù†ÛŒÙ…
                    if client.is_connected:
                        await client.stop()
                    logger.info(f"ÙØ§ÛŒÙ„ Ø¨Ø²Ø±Ú¯ {filepath} Ø¨Ø§ Pyrogram Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯")
                else:
                    raise Exception("Pyrogram client Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª")
            except Exception as e:
                logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ø¨Ø§ Pyrogram: {e}")
                raise
        else:
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Bot API Ù…Ø¹Ù…ÙˆÙ„ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú© (Ø²ÛŒØ± 50MB)
            with open(filepath, 'rb') as f:
                if content_type == 'image/gif':
                    # Ø§Ø±Ø³Ø§Ù„ GIF Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Animation
                    await update.message.reply_animation(
                        animation=f,
                        caption=f"ğŸï¸ GIF Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡\nğŸ“¦ Ø­Ø¬Ù…: {file_size_mb:.2f} MB\nğŸ• {current_time}",
                        read_timeout=300,
                        write_timeout=300,
                        connect_timeout=30,
                        pool_timeout=30
                    )
                elif is_video_file(filepath, content_type):
                    # Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ØµÙˆØ±Øª ÙˆÛŒØ¯ÛŒÙˆ
                    await update.message.reply_video(
                        video=f,
                        caption=f"ğŸ“¹ ÙˆÛŒØ¯ÛŒÙˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡\nğŸ“¦ Ø­Ø¬Ù…: {file_size_mb:.2f} MB\nğŸ• {current_time}",
                        supports_streaming=True,
                        read_timeout=300,
                        write_timeout=300,
                        connect_timeout=30,
                        pool_timeout=30
                    )
                else:
                    # Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ØµÙˆØ±Øª Ø³Ù†Ø¯
                    await update.message.reply_document(
                        document=f,
                        caption=f"ğŸ“„ ÙØ§ÛŒÙ„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡\nğŸ“¦ Ø­Ø¬Ù…: {file_size_mb:.2f} MB\nğŸ• {current_time}",
                        read_timeout=300,
                        write_timeout=300,
                        connect_timeout=30,
                        pool_timeout=30
                    )
        
        # Ø­Ø°Ù Ù¾ÛŒØ§Ù… ÙˆØ¶Ø¹ÛŒØª
        await status_message.delete()
        
        # Ø­Ø°Ù ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª
        os.remove(filepath)
        logger.info(f"ÙØ§ÛŒÙ„ {filepath} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ùˆ Ø­Ø°Ù Ø´Ø¯.")
    
    except asyncio.TimeoutError:
        logger.error("Ø®Ø·Ø§: Timeout Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„")
        await status_message.edit_text(
            "âŒ Ø²Ù…Ø§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÙ…Ø§Ù… Ø´Ø¯.\n"
            "Ø§ÛŒÙ† Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø­Ø¬Ù… Ø²ÛŒØ§Ø¯ ÙØ§ÛŒÙ„ ÛŒØ§ Ø³Ø±Ø¹Øª Ù¾Ø§ÛŒÛŒÙ† Ø§ÛŒÙ†ØªØ±Ù†Øª Ø¨Ø§Ø´Ø¯.\n"
            "Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ Ú©ÙˆÚ†Ú©â€ŒØªØ±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯."
        )
        if filepath and os.path.exists(filepath):
            os.remove(filepath)
        cleanup_partial_files()
    
    except MemoryError:
        logger.error("Ø®Ø·Ø§: Ú©Ù…Ø¨ÙˆØ¯ Ø­Ø§ÙØ¸Ù‡ (OOM)")
        await status_message.edit_text(
            "âŒ Ø­Ø§ÙØ¸Ù‡ Ø³Ø±ÙˆØ± Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª.\n"
            "Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ Ú©ÙˆÚ†Ú©â€ŒØªØ±ÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯."
        )
        if filepath and os.path.exists(filepath):
            os.remove(filepath)
        cleanup_partial_files()
        cleanup_old_files()
    
    except Exception as e:
        error_msg = str(e)
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„: {error_msg}")
        
        # Ù¾ÛŒØ§Ù… Ø®Ø·Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ù¾Ø³Ù†Ø¯
        if "timed out" in error_msg.lower() or "timeout" in error_msg.lower():
            user_msg = "âŒ Ø²Ù…Ø§Ù† Ø§ØªØµØ§Ù„ ØªÙ…Ø§Ù… Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯."
        elif "memory" in error_msg.lower() or "out of memory" in error_msg.lower():
            user_msg = "âŒ Ø­Ø§ÙØ¸Ù‡ Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ Ú©ÙˆÚ†Ú©â€ŒØªØ±ÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯."
        elif "connection" in error_msg.lower():
            user_msg = "âŒ Ù…Ø´Ú©Ù„ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø³Ø±ÙˆØ±. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯."
        else:
            user_msg = f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„: {error_msg[:100]}"
        
        await status_message.edit_text(user_msg)
        
        # Ø­Ø°Ù ÙØ§ÛŒÙ„ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§
        if filepath and os.path.exists(filepath):
            os.remove(filepath)
        cleanup_partial_files()


async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§Ù‡Ø§"""
    error_msg = str(context.error)
    logger.error(f"Ø®Ø·Ø§: {error_msg}")
    
    if update and update.message:
        if "timed out" in error_msg.lower() or "timeout" in error_msg.lower():
            await update.message.reply_text("âŒ Ø²Ù…Ø§Ù† Ø§ØªØµØ§Ù„ ØªÙ…Ø§Ù… Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.")
        elif "memory" in error_msg.lower():
            await update.message.reply_text("âŒ Ø­Ø§ÙØ¸Ù‡ Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ Ú©ÙˆÚ†Ú©â€ŒØªØ±ÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.")
        else:
            await update.message.reply_text("âŒ Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.")


def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø±Ø¨Ø§Øª"""
    # Ø¨Ø±Ø±Ø³ÛŒ ØªÙˆÚ©Ù†
    if not BOT_TOKEN:
        print("âŒ ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        print("Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ .env Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ ÛŒØ§ ØªÙˆÚ©Ù† Ø±Ø§ Ø¯Ø± Ú©Ø¯ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯.")
        return
    
    print(f"âœ… ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
    print(f"ğŸ”‘ API ID: {API_ID}")
    print(f"ğŸ“Š Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø­Ø¬Ù… ÙØ§ÛŒÙ„: {MAX_FILE_SIZE_MB} MB")
    
    # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ùˆ Ù†Ø§ØªÙ…Ø§Ù… Ø¯Ø± Ø§Ø³ØªØ§Ø±Øª
    print("ğŸ§¹ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ...")
    cleanup_old_files()
    cleanup_partial_files()
    cleanup_old_links()
    print("âœ… Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù„ Ø´Ø¯")
    
    # Ø´Ø±ÙˆØ¹ Flask server Ø¨Ø±Ø§ÛŒ keep-alive (Ø¨Ø±Ø§ÛŒ Render.com)
    try:
        from keep_alive import keep_alive
        keep_alive()
        print("ğŸŒ Flask server Ø¨Ø±Ø§ÛŒ keep-alive Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯")
    except ImportError:
        print("âš ï¸ keep_alive.py ÛŒØ§ÙØª Ù†Ø´Ø¯ - Ø¯Ø± Ø­Ø§Ù„Øª Ø¹Ø§Ø¯ÛŒ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯")
    
    # Ø³Ø§Ø®Øª Application Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ù¾Ø±Ø§Ú©Ø³ÛŒ Ùˆ ØªØ§ÛŒÙ…â€ŒØ§ÙˆØª Ø¨Ø§Ù„Ø§ Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯
    app_builder = Application.builder().token(BOT_TOKEN)
    
    # ØªÙ†Ø¸ÛŒÙ… HTTPXRequest Ø¨Ø§ ØªØ§ÛŒÙ…â€ŒØ§ÙˆØª Ø¨Ø§Ù„Ø§ Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯
    from telegram.request import HTTPXRequest
    request_kwargs = {
        'connection_pool_size': 8,
        'connect_timeout': 30.0,
        'read_timeout': 300.0,
        'write_timeout': 300.0,
        'pool_timeout': 30.0
    }
    
    # Ø§Ú¯Ø± Ù¾Ø±Ø§Ú©Ø³ÛŒ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡ØŒ Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
    if PROXY_URL:
        request_kwargs['proxy_url'] = PROXY_URL
        print(f"ğŸŒ Ù¾Ø±Ø§Ú©Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Telegram Bot ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯: {PROXY_URL}")
    
    request = HTTPXRequest(**request_kwargs)
    app_builder.request(request)
    print(f"âœ… ØªØ§ÛŒÙ…â€ŒØ§ÙˆØª Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯ (300 Ø«Ø§Ù†ÛŒÙ‡)")
    
    application = app_builder.build()
    
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("admin", admin_panel))
    application.add_handler(CommandHandler("check", check_user))
    application.add_handler(CallbackQueryHandler(admin_callback))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù‡Ù†Ø¯Ù„Ø± Ø®Ø·Ø§
    application.add_error_handler(error_handler)
    
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† job Ø¨Ø±Ø§ÛŒ Ú†Ú© Ø±ÙˆØ²Ø§Ù†Ù‡ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ù‚Ø¶Ø§
    job_queue = application.job_queue
    if job_queue is not None:
        # Ù‡Ø± 24 Ø³Ø§Ø¹Øª ÛŒÚ©Ø¨Ø§Ø± Ú†Ú© Ú©Ù†
        job_queue.run_repeating(
            lambda context: asyncio.create_task(check_and_notify_expiring_links(context.bot)),
            interval=86400,  # 24 Ø³Ø§Ø¹Øª
            first=10  # Ø§ÙˆÙ„ÛŒÙ† Ø§Ø¬Ø±Ø§ 10 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø¹Ø¯ Ø§Ø² Ø§Ø³ØªØ§Ø±Øª
        )
        print("â° Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ Ú†Ú© Ø±ÙˆØ²Ø§Ù†Ù‡ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ ÙØ¹Ø§Ù„ Ø´Ø¯")
    else:
        print("âš ï¸ JobQueue Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ø¨Ø±Ø§ÛŒ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒØŒ python-telegram-bot[job-queue] Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯.")
    
    # Ø´Ø±ÙˆØ¹ Ø±Ø¨Ø§Øª
    print("ğŸ¤– Ø±Ø¨Ø§Øª Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§ Ø§Ø³Øª...")
    print("Ø¨Ø±Ø§ÛŒ ØªÙˆÙ‚Ù Ø±Ø¨Ø§Øª Ø§Ø² Ctrl+C Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")
    application.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == '__main__':
    main()
